{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.nersc.gov/assets/Uploads/n-logo.png\" width=\"100\" align=\"right\">\n",
    "\n",
    "Jupyter Notebooks at NERSC (https://jupyter-dev.nersc.gov/)\n",
    "===========================================================\n",
    "\n",
    "There are currently 2 Jupyter notebook services running at NERSC.  One is running on a [Science Gateway Node](https://jupyter.nersc.gov) and is more of a production service.  The other is running on a dedicated data analytics node on [Cori](https://jupyter-dev.nersc.gov) and is more experimental (but open to users).  The second set up provides several advantages over the first.\n",
    "\n",
    "It's Really Running on Cori\n",
    "===========================\n",
    "\n",
    "Running `socket.gethostname()` on the SGN Jupyter service just returns a docker container ID, but here you can see it's actually on a Cori node dedicated to Jupyter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "socket.gethostname()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and there are 32 (Haswell) CPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "psutil.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and there is 500+ GB of memory available, much more than is available on the SGN Jupyter service: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "psutil.virtual_memory().total / 2**30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cori Scratch Access\n",
    "===================\n",
    "\n",
    "Access to Cori `$SCRATCH` is not possible from old Jupyter, but using Jupyter on Cori it is.  This is highly useful for people who need to analyze or visualize data stored on that file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.get(\"SCRATCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the Same Python Environment as at Cori Login\n",
    "=================================================\n",
    "\n",
    "That is, you get the same Python as when you log in and do `module load python` or `module load python/3.5-anaconda` and not a different Python stack on some other system.  This is helpful if you use both modes of interacting with Cori via Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access to the Cori Batch Queues\n",
    "===============================\n",
    "\n",
    "Jupyter supports \"%magic\" commands that expose functionality in code cells beyond the language kernel.  At NERSC we have set up [Slurm magic](https://github.com/NERSC/slurm-magic) commands to expose the Cori batch queue through Jupyter.  This is an admittedly limited but still useful mechanism for interacting with batch jobs.\n",
    "\n",
    "Slurm magic commands simply wrapper Slurm command line functionality, so most Slurm commands you use at the command line you just prefix with a \"%\" like so.  To see what's in the queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That might look different from _your_ `squeue` output.  Note that your `SQUEUE_FORMAT` environment variable is respected --- Jupyter on Cori observes your shell dotfile login setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.get(\"SQUEUE_FORMAT\", \"not defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to `squeue` though.  By default the output of this command is placed into a [Pandas](http://pandas.pydata.org/) dataframe object.  (Observe that you can also capture the result of a magic command as if it were just a Python function too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = %squeue\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a Pandas dataframe.  So if you get bored waiting for _your_ job to run, you can do some big data crunching on the Cori batch queue data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby(\"PARTITION\")[\"JOBID\"].count().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You Can Submit Jobs from Jupyter\n",
    "================================\n",
    "\n",
    "The `sbatch` command works two ways in Jupyter on Cori, either as a *line magic* or a *cell magic*.  The former would be useful for submitting existing batch scripts.  The latter lets you put the batch script _inside your Jupyter notebook._  Here's a trivial example to show we can run on 2 nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sbatch -p debug -t 10 -N 2 -C haswell\n",
    "#!/bin/bash\n",
    "srun -n 16 hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... little parsing of that response from sbatch to get the Job ID ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobid = _.split()[-1]\n",
    "jobid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%squeue -j $jobid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I was fast enough the above would be a data frame, and if the queue is not too slow the job should be running.  Below we look at the Slurm job output and should see 2 different compute node hostnames 8 times each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"slurm-{}.out\".format(jobid), \"r\") as stream:\n",
    "    print(stream.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "... But Wait There's More\n",
    "=========================\n",
    "\n",
    "See demonstrations and notebooks from other speakers here, including machine learning notebooks from Evan Racah (next speaker) and Lisa Gerhardt (Spark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
